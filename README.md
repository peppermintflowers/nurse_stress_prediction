# Stress Prediction Pipeline: Real-Time Kafka

A containerized Kafka streaming pipeline for processing worker stress data in real-time. Integrates with Java-based Flink for ML inference.

## Architecture

![sysarch](assets/architecture_diagram.png "sysarch")

## Flink Workflow
![sysarch](assets/flink_workflow.png "sysarch")

## Prerequisites

- **Docker Desktop** (with Docker Compose v2)
- **Git**
- **Java 17**
- **Python 3.8+** (for local development, optional)
- **2 GB+ available disk space**


## Quick Start For Primary Flink Workflow (5 minutes)

### 1. Clone the Repository

```bash
git clone https://github.com/peppermintflowers/nurse_stress_prediction.git
cd nurse_stress_prediction
```

### 2. Verify Docker is Running

```bash
docker --version
docker compose version
```

Both should output version info. If not, install Docker Desktop.

### 3. Start All Services

From the project root (`nurse_stress_prediction`), run:

```bash
docker compose up --build -d
```

This will:
- Pull/build all images 
- Start containers in detached mode
- CSV producer will immediately begin streaming data from csv files in `data/workers.csv.zip` to Kafka

### 4. Verify Services are Running

```bash
docker compose ps
```

### 5. Monitor the Pipeline

**Kafka UI Dashboard** (view topics & messages):
- Open http://localhost:8080 in your browser
- Navigate to **Topics** â†’ **stress-topic** to see messages flowing
  ![sysarch](assets/kafka-ui.png "sysarch")
- Open http://localhost:8081 in your browser
- Check that flink is up and two task slots are available
  ![sysarch](assets/flink-ui.png "sysarch")

**Producer Logs** (see data being sent):
```bash
docker compose logs csv-producer --tail 50 -f
```
**View Logs for other services**
```bash
# All services
docker compose logs -f

# Specific service
docker compose logs kafka -f
docker compose logs csv-producer -f
docker compose logs flink-jobmanager -f

# Last N lines
docker compose logs --tail 100
```

### 6. Build Flink Job Jar
- Run from project directory
```bash
cd flink-stress-data-processor
mvn clean package
```
- After executing the above commands the flink-stress-data-processor-1.0-SNAPSHOT.jar should get generated in the target folder of flink-stress-data-processor directory

### 7. Submit Flink Job Jar 
- Open http://localhost:8081 in your browser
- Navigate to
- Upload the jar file "flink-stress-data-processor-1.0-SNAPSHOT.jar" generated in previous step and submit the job
  ![sysarch](assets/flink_jar.png "sysarch")
- Verify that the job is running and that real-time watermarks are generated
  ![sysarch](assets/flink_job_running.png "sysarch")
  ![sysarch](assets/flink_watermark.png "sysarch")

### 8. Create dashboard in Grafana and visualise results
- Open http://localhost:3000 in your browser
- Use admin/admin as credentials
- Connect to InfluxDB 
- Use UI to build queries and create dashboards to visualise the real-time processed data
  ![sysarch](assets/dashboard.png "sysarch")


  ![sysarch](assets/panel1.png "sysarch")


  ![sysarch](assets/panel2.png "sysarch")


  ![sysarch](assets/panel3.png "sysarch")


  ![sysarch](assets/panel4.png "sysarch")


### Dask Fallback System

This project includes an **automatic fallback system** using Dask ML that activates when the primary Flink pipeline experiences resource constraints. The fallback ensures continuous stress monitoring without data loss.

**Key Features:**
- ðŸ”„ Automatic switching based on processing latency
- ðŸ“Š Processes larger batches (1000 messages) at lower frequency
- âœ… Zero data loss via Kafka checkpoints
- ðŸ”§ Fully configurable thresholds and batch sizes
- ðŸ“ˆ Writes to same InfluxDB with `source=dask-fallback` tag

**Quick Start:**
```bash
# System monitors automatically - no action needed
docker compose up -d

# View fallback status
docker compose logs dask-fallback -f

# Test the fallback
cd dask-fallback && ./test_fallback.sh
```

**Documentation:**
- ðŸ“– [Integration Guide](DASK_FALLBACK_INTEGRATION.md) - How it works with existing system
- ðŸ“š [Full Documentation](dask-fallback/README.md) - Detailed technical docs
- ðŸš€ [Quick Start](dask-fallback/QUICK_START.md) - Commands and tips

## Project Structure

```
.
â”œâ”€â”€ assets
â”‚Â Â  â”œâ”€â”€ architecture_diagram.png
â”‚Â Â  â””â”€â”€ flink_workflow.png
â”œâ”€â”€ DASK_FALLBACK_INTEGRATION.md
â”œâ”€â”€ dask-fallback
â”‚Â Â  â”œâ”€â”€ ARCHITECTURE.md
â”‚Â Â  â”œâ”€â”€ config.yaml
â”‚Â Â  â”œâ”€â”€ dask_processor.py
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ monitor.py
â”‚Â Â  â”œâ”€â”€ orchestrator.py
â”‚Â Â  â”œâ”€â”€ QUICK_START.md
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ requirements.txt
â”‚Â Â  â””â”€â”€ test_fallback.sh
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ create_topic.sh
â”‚Â Â  â”œâ”€â”€ data_processing_for_demo.ipynb
â”‚Â Â  â”œâ”€â”€ Dockerfile.producer
â”‚Â Â  â”œâ”€â”€ nurse_sensor_event.avsc
â”‚Â Â  â”œâ”€â”€ producer.py
â”‚Â Â  â”œâ”€â”€ requirements.txt
â”‚Â Â  â””â”€â”€ workers.csv.zip
â”œâ”€â”€ DEPLOYMENT_GUIDE.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ flask-predictor
â”‚Â Â  â”œâ”€â”€ app.py
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ model
â”‚Â Â  â”‚Â Â  â””â”€â”€ stress_prediction_model_lgbm.joblib
â”‚Â Â  â””â”€â”€ requirements.txt
â”œâ”€â”€ flink-stress-data-processor
â”‚Â Â  â”œâ”€â”€ dependency-reduced-pom.xml
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ pom.xml
â”‚Â Â  â”œâ”€â”€ src
â”‚Â Â  â”‚Â Â  â””â”€â”€ main
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ avro
â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ SensorRecord.avsc
â”‚Â Â  â”‚Â Â      â””â”€â”€ java
â”‚Â Â  â”‚Â Â          â””â”€â”€ com
â”‚Â Â  â”‚Â Â              â””â”€â”€ nurse
â”‚Â Â  â”‚Â Â                  â””â”€â”€ stress
â”‚Â Â  â”‚Â Â                      â””â”€â”€ prediction
â”‚Â Â  â”‚Â Â                          â”œâ”€â”€ model
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â”œâ”€â”€ IOTPing.java
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â””â”€â”€ NurseMetrics.java
â”‚Â Â  â”‚Â Â                          â”œâ”€â”€ processing
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â”œâ”€â”€ AverageAggregator.java
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â”œâ”€â”€ Constants.java
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â”œâ”€â”€ StressPredictionAsyncFunction.java
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â”œâ”€â”€ StressPredictorJob.java
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â”œâ”€â”€ WatermarkStrategyFactory.java
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â””â”€â”€ WindowResultFunction.java
â”‚Â Â  â”‚Â Â                          â”œâ”€â”€ sink
â”‚Â Â  â”‚Â Â                          â”‚Â Â  â””â”€â”€ InfluxSinkPing.java
â”‚Â Â  â”‚Â Â                          â””â”€â”€ source
â”‚Â Â  â”‚Â Â                              â””â”€â”€ KafkaSourceFactory.java
â”‚Â Â  â”œâ”€â”€ submit-job.sh
â”‚Â Â  â””â”€â”€ target
â”‚Â Â      â”œâ”€â”€ classes
â”‚Â Â      â”‚Â Â  â””â”€â”€ com
â”‚Â Â      â”‚Â Â      â””â”€â”€ nurse
â”‚Â Â      â”‚Â Â          â””â”€â”€ stress
â”‚Â Â      â”‚Â Â              â””â”€â”€ prediction
â”‚Â Â      â”‚Â Â                  â”œâ”€â”€ model
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ IOTPing.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â””â”€â”€ NurseMetrics.class
â”‚Â Â      â”‚Â Â                  â”œâ”€â”€ processing
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ AverageAggregator.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ Constants.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ StressPredictionAsyncFunction.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ StressPredictorJob.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ WatermarkStrategyFactory.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â”œâ”€â”€ WatermarkStrategyFactory$1.class
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â””â”€â”€ WindowResultFunction.class
â”‚Â Â      â”‚Â Â                  â”œâ”€â”€ SensorRecord.class
â”‚Â Â      â”‚Â Â                  â”œâ”€â”€ SensorRecord$1.class
â”‚Â Â      â”‚Â Â                  â”œâ”€â”€ SensorRecord$Builder.class
â”‚Â Â      â”‚Â Â                  â”œâ”€â”€ sink
â”‚Â Â      â”‚Â Â                  â”‚Â Â  â””â”€â”€ InfluxSinkPing.class
â”‚Â Â      â”‚Â Â                  â””â”€â”€ source
â”‚Â Â      â”‚Â Â                      â””â”€â”€ KafkaSourceFactory.class
â”‚Â Â      â”œâ”€â”€ flink-stress-data-processor-1.0-SNAPSHOT.jar
â”‚Â Â      â”œâ”€â”€ generated-sources
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ annotations
â”‚Â Â      â”‚Â Â  â””â”€â”€ avro
â”‚Â Â      â”‚Â Â      â””â”€â”€ com
â”‚Â Â      â”‚Â Â          â””â”€â”€ nurse
â”‚Â Â      â”‚Â Â              â””â”€â”€ stress
â”‚Â Â      â”‚Â Â                  â””â”€â”€ prediction
â”‚Â Â      â”‚Â Â                      â””â”€â”€ SensorRecord.java
â”‚Â Â      â”œâ”€â”€ maven-archiver
â”‚Â Â      â”‚Â Â  â””â”€â”€ pom.properties
â”‚Â Â      â”œâ”€â”€ maven-status
â”‚Â Â      â”‚Â Â  â””â”€â”€ maven-compiler-plugin
â”‚Â Â      â”‚Â Â      â””â”€â”€ compile
â”‚Â Â      â”‚Â Â          â””â”€â”€ default-compile
â”‚Â Â      â”‚Â Â              â”œâ”€â”€ createdFiles.lst
â”‚Â Â      â”‚Â Â              â””â”€â”€ inputFiles.lst
â”‚Â Â      â”œâ”€â”€ original-flink-stress-data-processor-1.0-SNAPSHOT.jar
â”‚Â Â      â””â”€â”€ project-local-repo
â”‚Â Â          â””â”€â”€ org.example
â”‚Â Â              â””â”€â”€ flink-stress-data-processor
â”‚Â Â                  â””â”€â”€ 1.0-SNAPSHOT
â”‚Â Â                      â”œâ”€â”€ flink-stress-data-processor-1.0-SNAPSHOT-consumer.pom
â”‚Â Â                      â”œâ”€â”€ flink-stress-data-processor-1.0-SNAPSHOT.jar
â”‚Â Â                      â””â”€â”€ flink-stress-data-processor-1.0-SNAPSHOT.pom
â”œâ”€â”€ grafana_dashboard_dual_source.json
â”œâ”€â”€ HOW_TO_USE_DASK_FALLBACK.md
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md
â”œâ”€â”€ ml_model
â”‚Â Â  â”œâ”€â”€ stress_model_training.py
â”‚Â Â  â”œâ”€â”€ stress_prediction_model_lgbm.joblib
â”‚Â Â  â””â”€â”€ stress_prediction_model.joblib
â”œâ”€â”€ README.md
â”œâ”€â”€ verify_both_sources.sh
â””â”€â”€ VERIFYING_DATA_FROM_BOTH_SOURCES.md

```

**Branch:** `main`  
**Created:** November 2025
